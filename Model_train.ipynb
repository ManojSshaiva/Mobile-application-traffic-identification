{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e67da32-88b9-4f10-ba60-b80c1ef8fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d42e8e94-bda2-4207-911c-23987af72230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed data\n",
    "data = pd.read_csv('Processed.csv')\n",
    "\n",
    "# Separate features and target labels\n",
    "X = data.drop('app', axis=1)  # Replace 'label' with the actual target column name\n",
    "y = data['app']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee296361-1634-4c7e-9fad-25f7025c3125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of components: 15\n"
     ]
    }
   ],
   "source": [
    "pca = PCA().fit(X_scaled)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_components = np.argmax(cumulative_variance >= 0.95) + 1  # Choose components that reach 95% variance\n",
    "print(\"Optimal number of components:\", n_components)\n",
    "\n",
    "# Applying PCA with optimal components\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4450d044-8e07-4251-bcbd-904735e320d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 2.0401 - val_loss: 1.6460\n",
      "Epoch 2/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9319 - val_loss: 1.5844\n",
      "Epoch 3/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.8022 - val_loss: 1.5315\n",
      "Epoch 4/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9527 - val_loss: 1.4885\n",
      "Epoch 5/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1284 - val_loss: 1.4532\n",
      "Epoch 6/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7735 - val_loss: 1.4216\n",
      "Epoch 7/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5900 - val_loss: 1.3961\n",
      "Epoch 8/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5451 - val_loss: 1.3732\n",
      "Epoch 9/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4961 - val_loss: 1.3535\n",
      "Epoch 10/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5626 - val_loss: 1.3356\n",
      "Epoch 11/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7097 - val_loss: 1.3189\n",
      "Epoch 12/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.3346 - val_loss: 1.3046\n",
      "Epoch 13/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4668 - val_loss: 1.2914\n",
      "Epoch 14/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8686 - val_loss: 1.2786\n",
      "Epoch 15/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.3780 - val_loss: 1.2676\n",
      "Epoch 16/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2449 - val_loss: 1.2569\n",
      "Epoch 17/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.4321 - val_loss: 1.2469\n",
      "Epoch 18/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.7751 - val_loss: 1.2375\n",
      "Epoch 19/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.3912 - val_loss: 1.2284\n",
      "Epoch 20/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5732 - val_loss: 1.2196\n",
      "Epoch 21/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2262 - val_loss: 1.2106\n",
      "Epoch 22/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2820 - val_loss: 1.2019\n",
      "Epoch 23/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2531 - val_loss: 1.1933\n",
      "Epoch 24/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5341 - val_loss: 1.1851\n",
      "Epoch 25/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2967 - val_loss: 1.1761\n",
      "Epoch 26/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2977 - val_loss: 1.1683\n",
      "Epoch 27/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2393 - val_loss: 1.1603\n",
      "Epoch 28/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1718 - val_loss: 1.1529\n",
      "Epoch 29/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2231 - val_loss: 1.1463\n",
      "Epoch 30/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2079 - val_loss: 1.1411\n",
      "Epoch 31/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3079 - val_loss: 1.1358\n",
      "Epoch 32/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3666 - val_loss: 1.1310\n",
      "Epoch 33/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4240 - val_loss: 1.1269\n",
      "Epoch 34/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2037 - val_loss: 1.1227\n",
      "Epoch 35/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4153 - val_loss: 1.1193\n",
      "Epoch 36/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2721 - val_loss: 1.1152\n",
      "Epoch 37/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7205 - val_loss: 1.1129\n",
      "Epoch 38/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4806 - val_loss: 1.1093\n",
      "Epoch 39/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5378 - val_loss: 1.1067\n",
      "Epoch 40/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4769 - val_loss: 1.1043\n",
      "Epoch 41/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3839 - val_loss: 1.1016\n",
      "Epoch 42/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6398 - val_loss: 1.0996\n",
      "Epoch 43/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3962 - val_loss: 1.0973\n",
      "Epoch 44/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3005 - val_loss: 1.0953\n",
      "Epoch 45/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3220 - val_loss: 1.0934\n",
      "Epoch 46/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9375 - val_loss: 1.0916\n",
      "Epoch 47/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4000 - val_loss: 1.0896\n",
      "Epoch 48/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7061 - val_loss: 1.0880\n",
      "Epoch 49/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3664 - val_loss: 1.0859\n",
      "Epoch 50/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4247 - val_loss: 1.0844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e086220f90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define autoencoder structure\n",
    "input_dim = X_pca.shape[1]\n",
    "encoding_dim = 25  # Latent space dimension, adjust as needed\n",
    "\n",
    "# Encoder\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
    "\n",
    "# Decoder\n",
    "decoder = Dense(input_dim, activation=\"sigmoid\")(encoder)\n",
    "\n",
    "# Autoencoder Model\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train autoencoder\n",
    "autoencoder.fit(X_pca, X_pca, epochs=50, batch_size=32, shuffle=True, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a4f654f-bc9d-4bf2-a4a3-2da8702e7184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs=input_layer, outputs=encoder)\n",
    "X_latent = encoder_model.predict(X_pca)\n",
    "# Split the data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_latent, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9537561d-ea76-4406-aed5-9d68bdb0805b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebbc13c5-85ac-444c-b8d9-be8806f25f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7203389830508474\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.46      0.48        13\n",
      "           2       0.67      0.50      0.57        16\n",
      "           3       0.89      0.93      0.91        44\n",
      "           4       0.71      0.68      0.70        22\n",
      "           5       0.87      0.89      0.88        46\n",
      "           6       0.73      0.90      0.81        63\n",
      "           7       0.58      0.70      0.64        10\n",
      "           8       0.67      0.24      0.35        17\n",
      "           9       0.50      0.46      0.48        13\n",
      "          10       0.54      0.35      0.42        20\n",
      "          11       0.43      0.55      0.48        22\n",
      "          12       0.82      0.72      0.77        39\n",
      "          13       0.62      0.89      0.73         9\n",
      "          14       0.75      0.75      0.75        20\n",
      "\n",
      "    accuracy                           0.72       354\n",
      "   macro avg       0.66      0.64      0.64       354\n",
      "weighted avg       0.72      0.72      0.71       354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate on test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c1164dd-e790-4b27-a3a5-ddb077d27f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Class 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.98      0.98       341\n",
      "        True       0.50      0.46      0.48        13\n",
      "\n",
      "    accuracy                           0.96       354\n",
      "   macro avg       0.74      0.72      0.73       354\n",
      "weighted avg       0.96      0.96      0.96       354\n",
      "\n",
      "\n",
      "Classification Report for Class 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.99      0.98       338\n",
      "        True       0.67      0.50      0.57        16\n",
      "\n",
      "    accuracy                           0.97       354\n",
      "   macro avg       0.82      0.74      0.78       354\n",
      "weighted avg       0.96      0.97      0.96       354\n",
      "\n",
      "\n",
      "Classification Report for Class 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.98      0.99       310\n",
      "        True       0.89      0.93      0.91        44\n",
      "\n",
      "    accuracy                           0.98       354\n",
      "   macro avg       0.94      0.96      0.95       354\n",
      "weighted avg       0.98      0.98      0.98       354\n",
      "\n",
      "\n",
      "Classification Report for Class 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.98      0.98       332\n",
      "        True       0.71      0.68      0.70        22\n",
      "\n",
      "    accuracy                           0.96       354\n",
      "   macro avg       0.85      0.83      0.84       354\n",
      "weighted avg       0.96      0.96      0.96       354\n",
      "\n",
      "\n",
      "Classification Report for Class 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.98      0.98       308\n",
      "        True       0.87      0.89      0.88        46\n",
      "\n",
      "    accuracy                           0.97       354\n",
      "   macro avg       0.93      0.94      0.93       354\n",
      "weighted avg       0.97      0.97      0.97       354\n",
      "\n",
      "\n",
      "Classification Report for Class 6:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.93      0.95       291\n",
      "        True       0.73      0.90      0.81        63\n",
      "\n",
      "    accuracy                           0.92       354\n",
      "   macro avg       0.85      0.92      0.88       354\n",
      "weighted avg       0.93      0.92      0.93       354\n",
      "\n",
      "\n",
      "Classification Report for Class 7:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99       344\n",
      "        True       0.58      0.70      0.64        10\n",
      "\n",
      "    accuracy                           0.98       354\n",
      "   macro avg       0.79      0.84      0.81       354\n",
      "weighted avg       0.98      0.98      0.98       354\n",
      "\n",
      "\n",
      "Classification Report for Class 8:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.99      0.98       337\n",
      "        True       0.67      0.24      0.35        17\n",
      "\n",
      "    accuracy                           0.96       354\n",
      "   macro avg       0.81      0.61      0.66       354\n",
      "weighted avg       0.95      0.96      0.95       354\n",
      "\n",
      "\n",
      "Classification Report for Class 9:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.98      0.98       341\n",
      "        True       0.50      0.46      0.48        13\n",
      "\n",
      "    accuracy                           0.96       354\n",
      "   macro avg       0.74      0.72      0.73       354\n",
      "weighted avg       0.96      0.96      0.96       354\n",
      "\n",
      "\n",
      "Classification Report for Class 10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.98      0.97       334\n",
      "        True       0.54      0.35      0.42        20\n",
      "\n",
      "    accuracy                           0.95       354\n",
      "   macro avg       0.75      0.67      0.70       354\n",
      "weighted avg       0.94      0.95      0.94       354\n",
      "\n",
      "\n",
      "Classification Report for Class 11:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.95      0.96       332\n",
      "        True       0.43      0.55      0.48        22\n",
      "\n",
      "    accuracy                           0.93       354\n",
      "   macro avg       0.70      0.75      0.72       354\n",
      "weighted avg       0.94      0.93      0.93       354\n",
      "\n",
      "\n",
      "Classification Report for Class 12:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.98      0.97       315\n",
      "        True       0.82      0.72      0.77        39\n",
      "\n",
      "    accuracy                           0.95       354\n",
      "   macro avg       0.89      0.85      0.87       354\n",
      "weighted avg       0.95      0.95      0.95       354\n",
      "\n",
      "\n",
      "Classification Report for Class 13:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.99      0.99       345\n",
      "        True       0.62      0.89      0.73         9\n",
      "\n",
      "    accuracy                           0.98       354\n",
      "   macro avg       0.81      0.94      0.86       354\n",
      "weighted avg       0.99      0.98      0.98       354\n",
      "\n",
      "\n",
      "Classification Report for Class 14:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99       334\n",
      "        True       0.75      0.75      0.75        20\n",
      "\n",
      "    accuracy                           0.97       354\n",
      "   macro avg       0.87      0.87      0.87       354\n",
      "weighted avg       0.97      0.97      0.97       354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_classes = data['app'].unique()\n",
    "for class_label in unique_classes:\n",
    "  y_true_binary = (y_test == class_label)\n",
    "  y_pred_binary = (y_pred == class_label)\n",
    "  print(f\"\\nClassification Report for Class {class_label}:\")\n",
    "  print(classification_report(y_true_binary, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1494e5ca-b9d4-473a-a0bc-4b9a8414fefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8813559322033898\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.75      0.60         4\n",
      "           2       0.75      0.60      0.67        10\n",
      "           3       1.00      0.97      0.98        32\n",
      "           4       0.87      1.00      0.93        13\n",
      "           5       1.00      0.93      0.97        30\n",
      "           6       0.93      1.00      0.96        40\n",
      "           7       0.80      0.89      0.84         9\n",
      "           8       0.43      0.33      0.38         9\n",
      "           9       0.56      0.62      0.59         8\n",
      "          10       0.90      0.64      0.75        14\n",
      "          11       0.81      0.81      0.81        16\n",
      "          12       0.90      0.93      0.91        28\n",
      "          13       1.00      1.00      1.00         6\n",
      "          14       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.88       236\n",
      "   macro avg       0.81      0.82      0.81       236\n",
      "weighted avg       0.88      0.88      0.88       236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#without scaling technique\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Processed.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['app'])\n",
    "y = data['app']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set \n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and display classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "709bdf88-e8c7-4069-a031-3974a2636f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.885593220338983\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.75      0.60         4\n",
      "           2       0.75      0.60      0.67        10\n",
      "           3       1.00      0.97      0.98        32\n",
      "           4       0.87      1.00      0.93        13\n",
      "           5       1.00      0.93      0.97        30\n",
      "           6       0.93      1.00      0.96        40\n",
      "           7       0.80      0.89      0.84         9\n",
      "           8       0.44      0.44      0.44         9\n",
      "           9       0.56      0.62      0.59         8\n",
      "          10       0.90      0.64      0.75        14\n",
      "          11       0.81      0.81      0.81        16\n",
      "          12       0.93      0.93      0.93        28\n",
      "          13       1.00      1.00      1.00         6\n",
      "          14       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.89       236\n",
      "   macro avg       0.82      0.83      0.82       236\n",
      "weighted avg       0.89      0.89      0.89       236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with standradization = z-score normalisation\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Processed.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['app'])\n",
    "y = data['app']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and display classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d00cea44-071b-4b15-b3d7-759560153c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Class 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.99      0.99       232\n",
      "        True       0.50      0.75      0.60         4\n",
      "\n",
      "    accuracy                           0.98       236\n",
      "   macro avg       0.75      0.87      0.80       236\n",
      "weighted avg       0.99      0.98      0.98       236\n",
      "\n",
      "\n",
      "Classification Report for Class 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.99      0.99       226\n",
      "        True       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       236\n",
      "   macro avg       0.87      0.80      0.83       236\n",
      "weighted avg       0.97      0.97      0.97       236\n",
      "\n",
      "\n",
      "Classification Report for Class 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00       204\n",
      "        True       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           1.00       236\n",
      "   macro avg       1.00      0.98      0.99       236\n",
      "weighted avg       1.00      1.00      1.00       236\n",
      "\n",
      "\n",
      "Classification Report for Class 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.99      1.00       223\n",
      "        True       0.87      1.00      0.93        13\n",
      "\n",
      "    accuracy                           0.99       236\n",
      "   macro avg       0.93      1.00      0.96       236\n",
      "weighted avg       0.99      0.99      0.99       236\n",
      "\n",
      "\n",
      "Classification Report for Class 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      1.00       206\n",
      "        True       1.00      0.93      0.97        30\n",
      "\n",
      "    accuracy                           0.99       236\n",
      "   macro avg       1.00      0.97      0.98       236\n",
      "weighted avg       0.99      0.99      0.99       236\n",
      "\n",
      "\n",
      "Classification Report for Class 6:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.98      0.99       196\n",
      "        True       0.93      1.00      0.96        40\n",
      "\n",
      "    accuracy                           0.99       236\n",
      "   macro avg       0.97      0.99      0.98       236\n",
      "weighted avg       0.99      0.99      0.99       236\n",
      "\n",
      "\n",
      "Classification Report for Class 7:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.99      0.99       227\n",
      "        True       0.80      0.89      0.84         9\n",
      "\n",
      "    accuracy                           0.99       236\n",
      "   macro avg       0.90      0.94      0.92       236\n",
      "weighted avg       0.99      0.99      0.99       236\n",
      "\n",
      "\n",
      "Classification Report for Class 8:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.98      0.98       227\n",
      "        True       0.44      0.44      0.44         9\n",
      "\n",
      "    accuracy                           0.96       236\n",
      "   macro avg       0.71      0.71      0.71       236\n",
      "weighted avg       0.96      0.96      0.96       236\n",
      "\n",
      "\n",
      "Classification Report for Class 9:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.98      0.98       228\n",
      "        True       0.56      0.62      0.59         8\n",
      "\n",
      "    accuracy                           0.97       236\n",
      "   macro avg       0.77      0.80      0.79       236\n",
      "weighted avg       0.97      0.97      0.97       236\n",
      "\n",
      "\n",
      "Classification Report for Class 10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      1.00      0.99       222\n",
      "        True       0.90      0.64      0.75        14\n",
      "\n",
      "    accuracy                           0.97       236\n",
      "   macro avg       0.94      0.82      0.87       236\n",
      "weighted avg       0.97      0.97      0.97       236\n",
      "\n",
      "\n",
      "Classification Report for Class 11:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99       220\n",
      "        True       0.81      0.81      0.81        16\n",
      "\n",
      "    accuracy                           0.97       236\n",
      "   macro avg       0.90      0.90      0.90       236\n",
      "weighted avg       0.97      0.97      0.97       236\n",
      "\n",
      "\n",
      "Classification Report for Class 12:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99       208\n",
      "        True       0.93      0.93      0.93        28\n",
      "\n",
      "    accuracy                           0.98       236\n",
      "   macro avg       0.96      0.96      0.96       236\n",
      "weighted avg       0.98      0.98      0.98       236\n",
      "\n",
      "\n",
      "Classification Report for Class 13:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00       230\n",
      "        True       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00       236\n",
      "   macro avg       1.00      1.00      1.00       236\n",
      "weighted avg       1.00      1.00      1.00       236\n",
      "\n",
      "\n",
      "Classification Report for Class 14:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00       219\n",
      "        True       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       236\n",
      "   macro avg       1.00      1.00      1.00       236\n",
      "weighted avg       1.00      1.00      1.00       236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_classes = data['app'].unique()\n",
    "for class_label in unique_classes:\n",
    "  y_true_binary = (y_test == class_label)\n",
    "  y_pred_binary = (y_pred == class_label)\n",
    "  print(f\"\\nClassification Report for Class {class_label}:\")\n",
    "  print(classification_report(y_true_binary, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "265c5296-8f12-45b4-9b8e-761b8a3edc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['traffic_classifier.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save trained models\n",
    "classifier_filename = 'traffic_classifier.pkl'\n",
    "\n",
    "import joblib\n",
    "joblib.dump(rf_model, classifier_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24fe0b46-5c6c-44b9-b41e-ad9dcd6251d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8728813559322034\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.75      0.55         4\n",
      "           2       0.75      0.60      0.67        10\n",
      "           3       1.00      0.97      0.98        32\n",
      "           4       0.75      0.92      0.83        13\n",
      "           5       0.96      0.87      0.91        30\n",
      "           6       0.93      1.00      0.96        40\n",
      "           7       0.80      0.89      0.84         9\n",
      "           8       0.50      0.44      0.47         9\n",
      "           9       0.60      0.75      0.67         8\n",
      "          10       0.89      0.57      0.70        14\n",
      "          11       0.81      0.81      0.81        16\n",
      "          12       0.96      0.93      0.95        28\n",
      "          13       1.00      1.00      1.00         6\n",
      "          14       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.87       236\n",
      "   macro avg       0.81      0.82      0.81       236\n",
      "weighted avg       0.88      0.87      0.87       236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize the features using MinMaxScaler\n",
    "normalizer = MinMaxScaler()\n",
    "X_normalized = normalizer.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets with normalized data\n",
    "X_train_norm, X_test_norm, y_train_norm, y_test_norm = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest model on normalized data\n",
    "rf_model_norm = RandomForestClassifier(random_state=42)\n",
    "rf_model_norm.fit(X_train_norm, y_train_norm)\n",
    "\n",
    "# Make predictions on the test set with normalized data\n",
    "y_pred_norm = rf_model_norm.predict(X_test_norm)\n",
    "\n",
    "# Calculate accuracy and classification report for the normalized data\n",
    "accuracy_norm = accuracy_score(y_test_norm, y_pred_norm)\n",
    "report_norm = classification_report(y_test_norm, y_pred_norm)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_norm}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98db8a21-705c-49b0-aabd-d437a7dcab3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Z-Score Standardization\n",
      "Accuracy: 0.885593220338983\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.75      0.60         4\n",
      "           2       0.75      0.60      0.67        10\n",
      "           3       1.00      0.97      0.98        32\n",
      "           4       0.87      1.00      0.93        13\n",
      "           5       1.00      0.93      0.97        30\n",
      "           6       0.93      1.00      0.96        40\n",
      "           7       0.80      0.89      0.84         9\n",
      "           8       0.44      0.44      0.44         9\n",
      "           9       0.56      0.62      0.59         8\n",
      "          10       0.90      0.64      0.75        14\n",
      "          11       0.81      0.81      0.81        16\n",
      "          12       0.93      0.93      0.93        28\n",
      "          13       1.00      1.00      1.00         6\n",
      "          14       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.89       236\n",
      "   macro avg       0.82      0.83      0.82       236\n",
      "weighted avg       0.89      0.89      0.89       236\n",
      "\n",
      "Using Min-Max Scaling\n",
      "Accuracy: 0.8728813559322034\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.75      0.55         4\n",
      "           2       0.75      0.60      0.67        10\n",
      "           3       1.00      0.97      0.98        32\n",
      "           4       0.75      0.92      0.83        13\n",
      "           5       0.96      0.87      0.91        30\n",
      "           6       0.93      1.00      0.96        40\n",
      "           7       0.80      0.89      0.84         9\n",
      "           8       0.50      0.44      0.47         9\n",
      "           9       0.60      0.75      0.67         8\n",
      "          10       0.89      0.57      0.70        14\n",
      "          11       0.81      0.81      0.81        16\n",
      "          12       0.96      0.93      0.95        28\n",
      "          13       1.00      1.00      1.00         6\n",
      "          14       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.87       236\n",
      "   macro avg       0.81      0.82      0.81       236\n",
      "weighted avg       0.88      0.87      0.87       236\n",
      "\n",
      "Using Max Absolute Scaling\n",
      "Accuracy: 0.8728813559322034\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.75      0.55         4\n",
      "           2       0.75      0.60      0.67        10\n",
      "           3       1.00      0.97      0.98        32\n",
      "           4       0.76      1.00      0.87        13\n",
      "           5       1.00      0.87      0.93        30\n",
      "           6       0.93      1.00      0.96        40\n",
      "           7       0.80      0.89      0.84         9\n",
      "           8       0.43      0.33      0.38         9\n",
      "           9       0.60      0.75      0.67         8\n",
      "          10       0.89      0.57      0.70        14\n",
      "          11       0.81      0.81      0.81        16\n",
      "          12       0.93      0.93      0.93        28\n",
      "          13       1.00      1.00      1.00         6\n",
      "          14       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.87       236\n",
      "   macro avg       0.81      0.82      0.80       236\n",
      "weighted avg       0.88      0.87      0.87       236\n",
      "\n",
      "Using Robust Scaling\n",
      "Accuracy: 0.885593220338983\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.75      0.60         4\n",
      "           2       0.75      0.60      0.67        10\n",
      "           3       1.00      0.97      0.98        32\n",
      "           4       0.87      1.00      0.93        13\n",
      "           5       1.00      0.93      0.97        30\n",
      "           6       0.93      1.00      0.96        40\n",
      "           7       0.80      0.89      0.84         9\n",
      "           8       0.44      0.44      0.44         9\n",
      "           9       0.56      0.62      0.59         8\n",
      "          10       0.90      0.64      0.75        14\n",
      "          11       0.81      0.81      0.81        16\n",
      "          12       0.93      0.93      0.93        28\n",
      "          13       1.00      1.00      1.00         6\n",
      "          14       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.89       236\n",
      "   macro avg       0.82      0.83      0.82       236\n",
      "weighted avg       0.89      0.89      0.89       236\n",
      "\n",
      "Using L2 Normalization\n",
      "Accuracy: 0.635593220338983\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.75      0.43         4\n",
      "           2       0.83      0.50      0.62        10\n",
      "           3       0.93      0.88      0.90        32\n",
      "           4       0.64      0.69      0.67        13\n",
      "           5       0.81      0.87      0.84        30\n",
      "           6       0.43      0.88      0.58        40\n",
      "           7       0.40      0.22      0.29         9\n",
      "           8       0.00      0.00      0.00         9\n",
      "           9       0.60      0.38      0.46         8\n",
      "          10       0.25      0.07      0.11        14\n",
      "          11       0.80      0.50      0.62        16\n",
      "          12       0.82      0.50      0.62        28\n",
      "          13       0.33      0.17      0.22         6\n",
      "          14       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.64       236\n",
      "   macro avg       0.57      0.52      0.51       236\n",
      "weighted avg       0.65      0.64      0.61       236\n",
      "\n",
      "\n",
      "Summary of Scaling Method Accuracies:\n",
      "Z-Score Standardization: 0.8856\n",
      "Min-Max Scaling: 0.8729\n",
      "Max Absolute Scaling: 0.8729\n",
      "Robust Scaling: 0.8856\n",
      "L2 Normalization: 0.6356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Processed.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['app'])\n",
    "y = data['app']\n",
    "\n",
    "# List of scalers to test\n",
    "scalers = {\n",
    "    \"Z-Score Standardization\": StandardScaler(),\n",
    "    \"Min-Max Scaling\": MinMaxScaler(),\n",
    "    \"Max Absolute Scaling\": MaxAbsScaler(),\n",
    "    \"Robust Scaling\": RobustScaler(),\n",
    "    \"L2 Normalization\": Normalizer(norm='l2')\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Iterate over each scaling method\n",
    "for name, scaler in scalers.items():\n",
    "    print(f\"Using {name}\")\n",
    "    \n",
    "    # Scale features\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize and train the model\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy and save results\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Classification Report\": report\n",
    "    }\n",
    "\n",
    "# Summary of results\n",
    "print(\"\\nSummary of Scaling Method Accuracies:\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name}: {metrics['Accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbde81de-dd57-4b81-8179-b53442ebdd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.885593220338983\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.75      0.60         4\n",
      "           2       0.75      0.60      0.67        10\n",
      "           3       1.00      0.97      0.98        32\n",
      "           4       0.87      1.00      0.93        13\n",
      "           5       1.00      0.93      0.97        30\n",
      "           6       0.93      1.00      0.96        40\n",
      "           7       0.80      0.89      0.84         9\n",
      "           8       0.44      0.44      0.44         9\n",
      "           9       0.56      0.62      0.59         8\n",
      "          10       0.90      0.64      0.75        14\n",
      "          11       0.81      0.81      0.81        16\n",
      "          12       0.93      0.93      0.93        28\n",
      "          13       1.00      1.00      1.00         6\n",
      "          14       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.89       236\n",
      "   macro avg       0.82      0.83      0.82       236\n",
      "weighted avg       0.89      0.89      0.89       236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#with standradization = z-score normalisation\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Processed.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['app'])\n",
    "y = data['app']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and display classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e42737c8-6c78-4612-bea4-ee9ebf83878a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_set.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing model\n",
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded file\n",
    "file_path = 'C:/Users/Lenovo/Documents/mini-project/Processed.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Sample 30 rows from the data\n",
    "sample_data = data.sample(n=30, random_state=1)\n",
    "\n",
    "# Save the sampled data to a new CSV file\n",
    "output_path = 'test_set.csv'\n",
    "sample_data.to_csv(output_path, index=False)\n",
    "\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f30724b7-9ea3-40d1-80cd-360883e30251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Actual  Predicted  result\n",
      "0        7          6   False\n",
      "1        6          6    True\n",
      "2       13         13    True\n",
      "3        5          5    True\n",
      "4       13         13    True\n",
      "5        3          3    True\n",
      "6        7          6   False\n",
      "7       14         13   False\n",
      "8       10          8   False\n",
      "9        6          6    True\n",
      "10      10         10    True\n",
      "11      14         14    True\n",
      "12       9          9    True\n",
      "13       4          5   False\n",
      "14      14         13   False\n",
      "15      14         14    True\n",
      "16       3          3    True\n",
      "17       5          5    True\n",
      "18       6          6    True\n",
      "19       3          3    True\n",
      "20      12         12    True\n",
      "21       4          4    True\n",
      "22       6          6    True\n",
      "23       3          3    True\n",
      "24       6          6    True\n",
      "25      12         12    True\n",
      "26       6          6    True\n",
      "27       2          1   False\n",
      "28      14         13   False\n",
      "29       7          6   False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('test_set.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['app'])\n",
    "y = data['app']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(X)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "results_df = pd.DataFrame({'Actual': y, 'Predicted': y_pred,'result':y==y_pred})\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c848d62f-98c1-4a40-9815-eaaefa39c263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.00%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (results_df['result'].sum() / len(results_df)) * 100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd3bb18f-9cde-4226-86c0-e409f7191eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for each class:\n",
      "app\n",
      "6     212\n",
      "3     157\n",
      "5     131\n",
      "12    112\n",
      "14     86\n",
      "11     72\n",
      "4      64\n",
      "10     62\n",
      "9      59\n",
      "7      56\n",
      "1      45\n",
      "13     45\n",
      "8      42\n",
      "2      37\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of samples for each class in the 'app' column\n",
    "cdata=pd.read_csv('Processed.csv')\n",
    "class_counts = cdata['app'].value_counts()\n",
    "\n",
    "print(\"Number of samples for each class:\")\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2375e4ca-9aa0-4cb7-9b9c-d5688a7bea63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1180\n"
     ]
    }
   ],
   "source": [
    "total_count = cdata['app'].value_counts().sum()\n",
    "print(total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6bd156ec-207e-4439-8d66-03b59d395af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "app\n",
      "6     212\n",
      "3     157\n",
      "5     131\n",
      "12    112\n",
      "14     86\n",
      "11     72\n",
      "4      64\n",
      "10     62\n",
      "9      59\n",
      "7      56\n",
      "1      45\n",
      "13     45\n",
      "8      42\n",
      "2      37\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Resampled class distribution:\n",
      "Counter({1: 212, 2: 212, 3: 212, 4: 212, 5: 212, 6: 212, 7: 212, 8: 212, 9: 212, 10: 212, 11: 212, 12: 212, 13: 212, 14: 212})\n",
      "\n",
      "Optimized Model Accuracy: 96.97%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.98      0.99        45\n",
      "           2       0.98      0.98      0.98        47\n",
      "           3       0.98      0.94      0.96        52\n",
      "           4       0.95      0.97      0.96        40\n",
      "           5       0.98      0.94      0.96        47\n",
      "           6       0.92      0.98      0.95        46\n",
      "           7       0.96      0.98      0.97        45\n",
      "           8       0.97      0.94      0.95        32\n",
      "           9       0.98      1.00      0.99        43\n",
      "          10       0.98      0.91      0.94        44\n",
      "          11       0.94      1.00      0.97        44\n",
      "          12       1.00      0.97      0.99        35\n",
      "          13       0.97      1.00      0.99        39\n",
      "          14       1.00      1.00      1.00        35\n",
      "\n",
      "    accuracy                           0.97       594\n",
      "   macro avg       0.97      0.97      0.97       594\n",
      "weighted avg       0.97      0.97      0.97       594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Processed.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['app'])\n",
    "y = data['app']\n",
    "\n",
    "# Print the initial class distribution\n",
    "print(\"Original class distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Step 1: Resampling - Use SMOTE for oversampling the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Print the resampled class distribution\n",
    "print(\"\\nResampled class distribution:\")\n",
    "print(Counter(y_resampled))\n",
    "\n",
    "# Step 2: Hyperparameter Tuning with GridSearchCV for Random Forest\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for RandomForest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best model after tuning\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 3: Evaluate the model performance on the test set\n",
    "y_pred = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nOptimized Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42f03258-6c40-4e8b-8a1f-76c0a86ba08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found by GridSearchCV:\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "\n",
      "Grid Search Results (Top 5 combinations):\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...         0.925441   \n",
      "1  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...         0.927124   \n",
      "2  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...         0.932600   \n",
      "3  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...         0.920806   \n",
      "4  {'max_depth': 10, 'min_samples_leaf': 1, 'min_...         0.923752   \n",
      "\n",
      "   std_test_score  rank_test_score  \n",
      "0        0.018675               59  \n",
      "1        0.011900               58  \n",
      "2        0.013196               55  \n",
      "3        0.011290               67  \n",
      "4        0.014520               62  \n"
     ]
    }
   ],
   "source": [
    "# After performing GridSearchCV and getting the best model\n",
    "print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# To see all the combinations of hyperparameters and their corresponding results:\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "# Convert the results to a DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Displaying the top few rows of the DataFrame to see the results of different hyperparameter combinations\n",
    "print(\"\\nGrid Search Results (Top 5 combinations):\")\n",
    "print(results_df[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23fdc2e4-aac5-4152-b81f-18b0b506724b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Actual  Predicted  result\n",
      "0        7          6   False\n",
      "1        6          6    True\n",
      "2       13         13    True\n",
      "3        5          5    True\n",
      "4       13         13    True\n",
      "5        3          3    True\n",
      "6        7          6   False\n",
      "7       14         14    True\n",
      "8       10         10    True\n",
      "9        6          6    True\n",
      "10      10         10    True\n",
      "11      14         14    True\n",
      "12       9          9    True\n",
      "13       4          4    True\n",
      "14      14         14    True\n",
      "15      14         14    True\n",
      "16       3          3    True\n",
      "17       5          5    True\n",
      "18       6          6    True\n",
      "19       3          3    True\n",
      "20      12         12    True\n",
      "21       4          4    True\n",
      "22       6          6    True\n",
      "23       3          3    True\n",
      "24       6          6    True\n",
      "25      12         12    True\n",
      "26       6          6    True\n",
      "27       2          1   False\n",
      "28      14         13   False\n",
      "29       7          6   False\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "test_data = pd.read_csv('test_set.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = test_data.drop(columns=['app'])\n",
    "y = test_data['app']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(X)\n",
    "\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "results_df = pd.DataFrame({'Actual': y, 'Predicted': y_pred,'result':y==y_pred})\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "caacae5d-2212-4696-9bf7-bf2935969fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (results_df['result'].sum() / len(results_df)) * 100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb8c2174-56b4-4ebf-a9d9-c6870dc39124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "app\n",
      "6     212\n",
      "3     157\n",
      "5     131\n",
      "12    112\n",
      "14     86\n",
      "11     72\n",
      "4      64\n",
      "10     62\n",
      "9      59\n",
      "7      56\n",
      "1      45\n",
      "13     45\n",
      "8      42\n",
      "2      37\n",
      "Name: count, dtype: int64\n",
      "Resampled dataset saved to 'balanced.csv'\n"
     ]
    }
   ],
   "source": [
    "# Resampling using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Processed.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['app'])\n",
    "y = data['app']\n",
    "\n",
    "# Print the initial class distribution\n",
    "print(\"Original class distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Step 1: Resampling - Use SMOTE for oversampling the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Combine the resampled features and target into a new DataFrame\n",
    "resampled_data = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "resampled_data['app'] = y_resampled\n",
    "\n",
    "# Save the resampled data to 'balanced_smote.csv'\n",
    "resampled_data.to_csv('balanced_smote.csv', index=False)\n",
    "\n",
    "print(\"Resampled dataset saved to 'balanced.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce2c05d1-d6a3-41ae-bedc-ebed7c0a8f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "app\n",
      "6     212\n",
      "3     157\n",
      "5     131\n",
      "12    112\n",
      "14     86\n",
      "11     72\n",
      "4      64\n",
      "10     62\n",
      "9      59\n",
      "7      56\n",
      "1      45\n",
      "13     45\n",
      "8      42\n",
      "2      37\n",
      "Name: count, dtype: int64\n",
      "Resampled dataset saved to 'balanced_smoteenn.csv'\n"
     ]
    }
   ],
   "source": [
    "# Resampling using smote-enn\n",
    "from imblearn.combine import SMOTEENN\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Processed.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['app'])\n",
    "y = data['app']\n",
    "\n",
    "# Print the initial class distribution\n",
    "print(\"Original class distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Step 1: Resampling - Use SMOTEENN for oversampling and noise removal\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "\n",
    "# Combine the resampled features and target into a new DataFrame\n",
    "resampled_data = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "resampled_data['app'] = y_resampled\n",
    "\n",
    "# Save the resampled data to 'balanced_smoteenn.csv'\n",
    "resampled_data.to_csv('balanced_smoteenn.csv', index=False)\n",
    "\n",
    "print(\"Resampled dataset saved to 'balanced_smoteenn.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b96bd00-bf1e-4e80-89b3-4dc678648092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resampled class distribution:\n",
      "Counter({3: 167, 5: 165, 4: 134, 2: 116, 12: 116, 13: 111, 14: 96, 6: 94, 11: 91, 9: 81, 10: 80, 1: 75, 8: 59, 7: 58})\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResampled class distribution:\")\n",
    "print(Counter(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc5e22d-5cff-40d3-bf15-10a7b7a7fcab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
