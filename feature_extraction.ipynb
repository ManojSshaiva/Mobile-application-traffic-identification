{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99aefbf2-e708-487c-8104-79f45373a060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a42cd2-8402-4ef6-a662-1495bc38a218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dropbox' 'facebook' 'gmail' 'google-drive' 'google-maps' 'hangout'\n",
      " 'hulu' 'instagram' 'messenger' 'netflix' 'pinterest' 'reddit' 'spotify'\n",
      " 'twitter' 'youtube'] 15 3438\n",
      "['dropbox_download' 'dropbox_upload' 'facebook_scroll-newsfeed'\n",
      " 'facebook_search-page' 'gmail_open-email' 'google-drive_download'\n",
      " 'google-drive_upload' 'google-maps_browse' 'google-maps_directions'\n",
      " 'google-maps_download-map' 'google-maps_explore' 'hangout_hangout'\n",
      " 'hulu_scroll-home' 'hulu_watch-video' 'instagram_IgSearchBrowse'\n",
      " 'messenger_send-message' 'netflix_browse-home' 'netflix_watch-video'\n",
      " 'pinterest_tap-board' 'reddit_browse' 'reddit_post' 'spotify_play-music'\n",
      " 'spotify_search-music' 'twitter_post-tweet' 'twitter_scroll-feed'\n",
      " 'youtube_catSearch' 'youtube_play-video'] 27\n",
      "                                               dropbox  \\\n",
      "0    dropbox_download_2019-03-16_10-50-30_4fd1c357.csv   \n",
      "1    dropbox_download_2019-03-16_10-50-30_5bd0c615.csv   \n",
      "2    dropbox_download_2019-03-16_11-12-14_5bd0c615.csv   \n",
      "3    dropbox_download_2019-03-16_11-31-23_4fd1c357.csv   \n",
      "4    dropbox_download_2019-03-16_11-31-34_5bd0c615.csv   \n",
      "..                                                 ...   \n",
      "476                                               None   \n",
      "477                                               None   \n",
      "478                                               None   \n",
      "479                                               None   \n",
      "480                                               None   \n",
      "\n",
      "                                              facebook  \\\n",
      "0    facebook_scroll-newsfeed_2019-03-16_09-29-11_4...   \n",
      "1    facebook_scroll-newsfeed_2019-03-16_09-32-03_4...   \n",
      "2    facebook_scroll-newsfeed_2019-03-16_09-33-23_4...   \n",
      "3    facebook_scroll-newsfeed_2019-03-16_10-51-41_4...   \n",
      "4    facebook_scroll-newsfeed_2019-03-16_10-51-42_5...   \n",
      "..                                                 ...   \n",
      "476                                               None   \n",
      "477                                               None   \n",
      "478                                               None   \n",
      "479                                               None   \n",
      "480                                               None   \n",
      "\n",
      "                                                 gmail  \\\n",
      "0    gmail_open-email_2019-03-16_10-53-03_4fd1c357.csv   \n",
      "1    gmail_open-email_2019-03-16_10-53-05_5bd0c615.csv   \n",
      "2    gmail_open-email_2019-03-16_11-33-52_5bd0c615.csv   \n",
      "3    gmail_open-email_2019-03-16_11-40-18_5bd0c615.csv   \n",
      "4    gmail_open-email_2019-03-16_11-42-03_4fd1c357.csv   \n",
      "..                                                 ...   \n",
      "476                                               None   \n",
      "477                                               None   \n",
      "478                                               None   \n",
      "479                                               None   \n",
      "480                                               None   \n",
      "\n",
      "                                          google-drive  \\\n",
      "0    google-drive_download_2019-03-16_09-28-20_4fd1...   \n",
      "1    google-drive_download_2019-03-16_10-53-27_4fd1...   \n",
      "2    google-drive_download_2019-03-16_10-53-29_5bd0...   \n",
      "3    google-drive_download_2019-03-16_11-32-53_5bd0...   \n",
      "4    google-drive_download_2019-03-16_11-52-30_5bd0...   \n",
      "..                                                 ...   \n",
      "476                                               None   \n",
      "477                                               None   \n",
      "478                                               None   \n",
      "479                                               None   \n",
      "480                                               None   \n",
      "\n",
      "                                           google-maps  \\\n",
      "0    google-maps_browse_2019-03-16_10-56-21_5bd0c61...   \n",
      "1    google-maps_browse_2019-03-16_10-56-24_4fd1c35...   \n",
      "2    google-maps_browse_2019-03-16_11-13-57_5bd0c61...   \n",
      "3    google-maps_browse_2019-03-16_11-26-28_4fd1c35...   \n",
      "4    google-maps_browse_2019-03-16_11-36-00_5bd0c61...   \n",
      "..                                                 ...   \n",
      "476  google-maps_explore_2019-03-17_11-36-22_4fd1c3...   \n",
      "477  google-maps_explore_2019-03-17_11-38-36_4fd1c3...   \n",
      "478  google-maps_explore_2019-03-17_11-41-24_4fd1c3...   \n",
      "479  google-maps_explore_2019-03-17_12-14-42_4fd1c3...   \n",
      "480  google-maps_explore_2019-03-17_12-15-39_4fd1c3...   \n",
      "\n",
      "                                              hangout  \\\n",
      "0    hangout_hangout_2019-03-16_12-19-56_5bd0c615.csv   \n",
      "1    hangout_hangout_2019-03-16_14-38-58_4fd1c357.csv   \n",
      "2    hangout_hangout_2019-03-16_14-54-17_4fd1c357.csv   \n",
      "3    hangout_hangout_2019-03-16_14-58-34_5bd0c615.csv   \n",
      "4    hangout_hangout_2019-03-16_15-00-33_5bd0c615.csv   \n",
      "..                                                ...   \n",
      "476                                              None   \n",
      "477                                              None   \n",
      "478                                              None   \n",
      "479                                              None   \n",
      "480                                              None   \n",
      "\n",
      "                                                  hulu  \\\n",
      "0    hulu_scroll-home_2019-03-21_00-00-24_5bd0c615.csv   \n",
      "1    hulu_scroll-home_2019-03-21_00-11-50_5bd0c615.csv   \n",
      "2    hulu_scroll-home_2019-03-21_00-13-39_5bd0c615.csv   \n",
      "3    hulu_scroll-home_2019-03-21_00-14-17_5bd0c615.csv   \n",
      "4    hulu_scroll-home_2019-03-21_00-14-55_5bd0c615.csv   \n",
      "..                                                 ...   \n",
      "476                                               None   \n",
      "477                                               None   \n",
      "478                                               None   \n",
      "479                                               None   \n",
      "480                                               None   \n",
      "\n",
      "                                             instagram  \\\n",
      "0    instagram_IgSearchBrowse_2019-03-16_09-27-12_4...   \n",
      "1    instagram_IgSearchBrowse_2019-03-16_11-49-39_5...   \n",
      "2    instagram_IgSearchBrowse_2019-03-16_12-02-06_4...   \n",
      "3    instagram_IgSearchBrowse_2019-03-16_12-10-37_4...   \n",
      "4    instagram_IgSearchBrowse_2019-03-16_14-41-38_5...   \n",
      "..                                                 ...   \n",
      "476                                               None   \n",
      "477                                               None   \n",
      "478                                               None   \n",
      "479                                               None   \n",
      "480                                               None   \n",
      "\n",
      "                                             messenger  \\\n",
      "0    messenger_send-message_2019-03-16_09-27-38_5bd...   \n",
      "1    messenger_send-message_2019-03-16_11-39-07_4fd...   \n",
      "2    messenger_send-message_2019-03-16_11-51-56_4fd...   \n",
      "3    messenger_send-message_2019-03-16_12-09-39_4fd...   \n",
      "4    messenger_send-message_2019-03-16_14-39-38_4fd...   \n",
      "..                                                 ...   \n",
      "476                                               None   \n",
      "477                                               None   \n",
      "478                                               None   \n",
      "479                                               None   \n",
      "480                                               None   \n",
      "\n",
      "                                               netflix  \\\n",
      "0    netflix_browse-home_2019-03-16_09-29-29_5bd0c6...   \n",
      "1    netflix_browse-home_2019-03-16_09-30-14_5bd0c6...   \n",
      "2    netflix_browse-home_2019-03-16_11-26-28_5bd0c6...   \n",
      "3    netflix_browse-home_2019-03-16_11-41-06_4fd1c3...   \n",
      "4    netflix_browse-home_2019-03-16_11-43-10_5bd0c6...   \n",
      "..                                                 ...   \n",
      "476                                               None   \n",
      "477                                               None   \n",
      "478                                               None   \n",
      "479                                               None   \n",
      "480                                               None   \n",
      "\n",
      "                                             pinterest  \\\n",
      "0    pinterest_tap-board_2019-03-16_09-30-15_4fd1c3...   \n",
      "1    pinterest_tap-board_2019-03-16_11-27-10_4fd1c3...   \n",
      "2    pinterest_tap-board_2019-03-16_11-54-42_5bd0c6...   \n",
      "3    pinterest_tap-board_2019-03-16_12-03-51_4fd1c3...   \n",
      "4    pinterest_tap-board_2019-03-16_12-13-12_4fd1c3...   \n",
      "..                                                 ...   \n",
      "476                                               None   \n",
      "477                                               None   \n",
      "478                                               None   \n",
      "479                                               None   \n",
      "480                                               None   \n",
      "\n",
      "                                             reddit  \\\n",
      "0    reddit_browse_2019-03-16_09-32-08_5bd0c615.csv   \n",
      "1    reddit_browse_2019-03-16_12-01-57_5bd0c615.csv   \n",
      "2    reddit_browse_2019-03-16_12-12-28_5bd0c615.csv   \n",
      "3    reddit_browse_2019-03-16_12-19-28_4fd1c357.csv   \n",
      "4    reddit_browse_2019-03-16_14-41-21_4fd1c357.csv   \n",
      "..                                              ...   \n",
      "476                                            None   \n",
      "477                                            None   \n",
      "478                                            None   \n",
      "479                                            None   \n",
      "480                                            None   \n",
      "\n",
      "                                               spotify  \\\n",
      "0    spotify_play-music_2019-03-16_17-25-05_5bd0c61...   \n",
      "1    spotify_play-music_2019-03-21_00-01-03_5bd0c61...   \n",
      "2    spotify_play-music_2019-03-21_00-08-34_5bd0c61...   \n",
      "3    spotify_play-music_2019-03-21_00-09-01_5bd0c61...   \n",
      "4    spotify_play-music_2019-03-21_00-16-11_5bd0c61...   \n",
      "..                                                 ...   \n",
      "476                                               None   \n",
      "477                                               None   \n",
      "478                                               None   \n",
      "479                                               None   \n",
      "480                                               None   \n",
      "\n",
      "                                               twitter  \\\n",
      "0    twitter_post-tweet_2019-03-20_23-59-58_5bd0c61...   \n",
      "1    twitter_post-tweet_2019-03-21_00-18-13_5bd0c61...   \n",
      "2    twitter_post-tweet_2019-03-21_00-34-10_5bd0c61...   \n",
      "3    twitter_post-tweet_2019-03-21_00-40-41_5bd0c61...   \n",
      "4    twitter_post-tweet_2019-03-21_00-44-02_5bd0c61...   \n",
      "..                                                 ...   \n",
      "476                                               None   \n",
      "477                                               None   \n",
      "478                                               None   \n",
      "479                                               None   \n",
      "480                                               None   \n",
      "\n",
      "                                               youtube  \n",
      "0    youtube_catSearch_2019-03-16_09-27-12_5bd0c615...  \n",
      "1    youtube_catSearch_2019-03-16_11-30-46_4fd1c357...  \n",
      "2    youtube_catSearch_2019-03-16_11-38-11_4fd1c357...  \n",
      "3    youtube_catSearch_2019-03-16_11-54-08_5bd0c615...  \n",
      "4    youtube_catSearch_2019-03-16_11-55-50_5bd0c615...  \n",
      "..                                                 ...  \n",
      "476                                               None  \n",
      "477                                               None  \n",
      "478                                               None  \n",
      "479                                               None  \n",
      "480                                               None  \n",
      "\n",
      "[481 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Define the scenario and the data path accordingly\n",
    "scenario = 'deterministic'  # deterministic, random, or wild\n",
    "if scenario == 'random':\n",
    "    mypath = './Data/Randomized Automated Data'\n",
    "elif scenario == 'deterministic':\n",
    "    mypath = 'C:/Users/Lenovo/Documents/mini-project/UTMobileNet2021/Deterministic Automated Data'\n",
    "elif scenario == 'wild':\n",
    "    mypath = 'C:/Users/Lenovo/Documents/mini-project/UTMobileNet2021/Wild Test Data'\n",
    "else:\n",
    "    raise NameError('Dataset Not Supported')\n",
    "\n",
    "# List all files in the specified directory\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "# Extract unique apps and actions\n",
    "apps = np.unique([f.split('_')[0] for f in onlyfiles])\n",
    "print(apps, len(apps), len(onlyfiles))\n",
    "app_actions = np.unique(['_'.join(f.split('_')[:2]) for f in onlyfiles])\n",
    "print(app_actions, len(app_actions))\n",
    "\n",
    "# Select applications and organize files\n",
    "sel_apps = apps\n",
    "sel_app_files = {app: [] for app in sel_apps}\n",
    "\n",
    "for fname in onlyfiles:\n",
    "    app_name = fname.split('_')[0]\n",
    "    if app_name in sel_apps:\n",
    "        sel_app_files[app_name].append(fname)\n",
    "\n",
    "# Optional: Convert the dictionary to a DataFrame for better manipulation later\n",
    "# This part is optional, depending on how you plan to use sel_app_files later\n",
    "sel_app_files_df = pd.DataFrame.from_dict(sel_app_files, orient='index').transpose()\n",
    "print(sel_app_files_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9f61e5a-5153-4569-b9c6-5c5346b35030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing flows\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define flow columns\n",
    "flow_columns = ['ip.src', 'srcport', 'ip.dst', 'dstport', 'protocol']\n",
    "\n",
    "def get_protocol(row):\n",
    "    if not pd.isnull(row['tcp.len']):\n",
    "        return 'TCP'\n",
    "    elif not pd.isnull(row['udp.length']):\n",
    "        return 'UDP'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    \n",
    "def get_src_port(row):\n",
    "    if not pd.isnull(row['tcp.len']):\n",
    "        return row['tcp.srcport']\n",
    "    elif not pd.isnull(row['udp.length']):\n",
    "        return row['udp.srcport']\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    \n",
    "def get_dst_port(row):\n",
    "    if not pd.isnull(row['tcp.len']):\n",
    "        return row['tcp.dstport']\n",
    "    elif not pd.isnull(row['udp.length']):\n",
    "        return row['udp.dstport']\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    \n",
    "columns = [\n",
    "    'frame.number', 'frame.time', 'frame.len', 'frame.cap_len', 'ip.hdr_len',\n",
    "    'ip.dsfield.ecn', 'ip.len', 'ip.frag_offset', 'ip.ttl', 'ip.proto',\n",
    "    'ip.src', 'ip.dst', 'tcp.hdr_len', 'tcp.len', 'tcp.srcport',\n",
    "    'tcp.dstport', 'tcp.flags.ns', 'tcp.flags.fin', 'tcp.window_size_value',\n",
    "    'tcp.urgent_pointer', 'tcp.option_kind', 'tcp.option_len',\n",
    "    'udp.srcport', 'udp.dstport', 'udp.length'\n",
    "]\n",
    "\n",
    "def compute_flow_features(df):\n",
    "    flow_features = {}\n",
    "    flow_features['total_num_pkts'] = len(df)\n",
    "    pkt_size = df['ip.len'].astype(float)\n",
    "    flow_features['total_num_bytes'] = pkt_size.sum()\n",
    "    flow_features['min_pkt_size'] = pkt_size.min()\n",
    "    flow_features['max_pkt_size'] = pkt_size.max()\n",
    "    flow_features['mean_pkt_size'] = pkt_size.mean()\n",
    "    flow_features['std_pkt_size'] = pkt_size.std()\n",
    "\n",
    "    # df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True))\n",
    "    # df['frame.time'] = df['frame.time'].dt.tz_localize('America/Chicago')\n",
    "    # iat = df['frame.time'].diff(1).dt.total_seconds().iloc[1:]\n",
    "\n",
    "    df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
    "    df['frame.time'] = df['frame.time'].dt.tz_localize('America/Chicago', ambiguous='NaT', nonexistent='NaT')\n",
    "    iat = df['frame.time'].diff().dt.total_seconds().iloc[1:]\n",
    "    \n",
    "    flow_features['min_iat'] = iat.min()\n",
    "    flow_features['max_iat'] = iat.max()\n",
    "    flow_features['mean_iat'] = iat.mean()\n",
    "    flow_features['std_iat'] = iat.std()\n",
    "    flow_features['dur'] = iat.sum()\n",
    "    \n",
    "    return flow_features\n",
    "\n",
    "def process_df_by_flow(df):\n",
    "    df['protocol'] = df.apply(get_protocol, axis=1)\n",
    "    df['srcport'] = df.apply(get_src_port, axis=1)\n",
    "    df['dstport'] = df.apply(get_dst_port, axis=1)\n",
    "    \n",
    "    df_flow = pd.DataFrame()\n",
    "    ul_flows = {}\n",
    "    dl_flows = {}\n",
    "\n",
    "    for flow, flow_df in df.groupby(by=flow_columns): \n",
    "        if flow[0].split('.')[0] == '10': #if ip.src starts with 10 then\n",
    "            ul_flows[flow] = compute_flow_features(flow_df)\n",
    "        else:\n",
    "            dl_flows[flow] = compute_flow_features(flow_df)\n",
    "\n",
    "    for ul_flow, ul_flow_features in ul_flows.items():\n",
    "        for dl_flow, dl_flow_features in dl_flows.items():\n",
    "            if (ul_flow[0] == dl_flow[2] and # ip.add src of ul == ip.add dest of dl\n",
    "                ul_flow[2] == dl_flow[0] and # ip.add dest of ul == ip.add src of dl\n",
    "                ul_flow[1] == dl_flow[3] and # ip.port src of ul == ip.port dest of dl\n",
    "                ul_flow[3] == dl_flow[1] and # ip.port dest of ul == ip.port src of dl\n",
    "                ul_flow[4] == dl_flow[4]): # protocol is same for ul and dl\n",
    "                \n",
    "                ul_flow_features = {'ul_' + feature_name: feature for feature_name, feature in ul_flow_features.items()}\n",
    "                dl_flow_features = {'dl_' + feature_name: feature for feature_name, feature in dl_flow_features.items()}\n",
    "                bi_flow_features = {**ul_flow_features, **dl_flow_features}\n",
    "                bi_flow_features['ip_A'] = ul_flow[0] #src\n",
    "                bi_flow_features['port_A'] = ul_flow[1]\n",
    "                bi_flow_features['ip_B'] = ul_flow[2] #dest\n",
    "                bi_flow_features['port_B'] = ul_flow[3]\n",
    "                bi_flow_features['protocol'] = ul_flow[4]\n",
    "\n",
    "                df_flow = pd.concat([df_flow, pd.DataFrame([bi_flow_features])], ignore_index=True)\n",
    "\n",
    "    return df_flow\n",
    "\n",
    "def clean_up_duplicate(row):\n",
    "    # row['ip.hdr_len'] = str(row['ip.hdr_len']).split(',')[-1]  # Keep the last one\n",
    "    row['ip.hdr_len'] = float(str(row['ip.hdr_len']).split(',')[-1]) if str(row['ip.hdr_len']).split(',')[-1].isdigit() else np.nan\n",
    "    row['ip.len'] = str(row['ip.len']).split(',')[0]  # Keep the first one\n",
    "    row['ip.src'] = row['ip.src'].split(',')[0]  # Keep the first one\n",
    "    row['ip.dst'] = row['ip.dst'].split(',')[0]  # Keep the first one\n",
    "    return row\n",
    "\n",
    "print(\"Done processing flows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb7f6a3d-8eb0-4b82-bcde-9b263198a72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:105: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  row['ip.len'] = str(row['ip.len']).split(',')[0]  # Keep the first one\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:105: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  row['ip.len'] = str(row['ip.len']).split(',')[0]  # Keep the first one\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:105: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  row['ip.len'] = str(row['ip.len']).split(',')[0]  # Keep the first one\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:105: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  row['ip.len'] = str(row['ip.len']).split(',')[0]  # Keep the first one\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5304\\1776596119.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['frame.time'] = pd.to_datetime(df['frame.time'].str.replace(r' CDT$', '', regex=True), errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing deterministic scenario data.\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.DataFrame()\n",
    "for app in sel_apps:\n",
    "    integrity = True\n",
    "    df_app = pd.DataFrame()\n",
    "    for fname in sel_app_files[app]:\n",
    "        action = fname.split('_')[1]\n",
    "        try:\n",
    "            df = pd.read_csv(join(mypath, fname), usecols=columns, low_memory=False)\n",
    "            df = df[df['ip.src'].notna()]\n",
    "            df = df.apply(lambda row: clean_up_duplicate(row), axis=1)\n",
    "\n",
    "            # Remove self loop pkts\n",
    "            df = df[(df['ip.src'] != '127.0.0.1') & (df['ip.dst'] != '127.0.0.1')]\n",
    "\n",
    "            df_flow = process_df_by_flow(df)\n",
    "            df_flow['action'] = action\n",
    "            df_app = pd.concat([df_app, df_flow], ignore_index=True)  # Use pd.concat here\n",
    "\n",
    "        except Exception as e:\n",
    "            integrity = False\n",
    "            print(f'\\n Error while processing {fname}. Error message: {str(e)} \\n')\n",
    "\n",
    "    df_app['app'] = app\n",
    "    \n",
    "    if integrity:\n",
    "        df_all = pd.concat([df_all, df_app], ignore_index=True)  # Use pd.concat here\n",
    "\n",
    "df_all.to_csv(f'./{scenario}_scenario_bi_flow_features.csv')\n",
    "print('Finished processing {} scenario data.'.format(scenario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1da702cb-9fb4-4100-ab29-ed92b2be6773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ul_total_num_pkts', 'ul_total_num_bytes',\n",
       "       'ul_min_pkt_size', 'ul_max_pkt_size', 'ul_mean_pkt_size',\n",
       "       'ul_std_pkt_size', 'ul_min_iat', 'ul_max_iat', 'ul_mean_iat',\n",
       "       'ul_std_iat', 'ul_dur', 'dl_total_num_pkts', 'dl_total_num_bytes',\n",
       "       'dl_min_pkt_size', 'dl_max_pkt_size', 'dl_mean_pkt_size',\n",
       "       'dl_std_pkt_size', 'dl_min_iat', 'dl_max_iat', 'dl_mean_iat',\n",
       "       'dl_std_iat', 'dl_dur', 'ip_A', 'port_A', 'ip_B', 'port_B', 'protocol',\n",
       "       'action', 'app'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df=pd.read_csv('wild_scenario_bi_flow_features.csv')\n",
    "processed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e498d184-8747-4f7d-b7f8-69fc9db11418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
